认为GNN的分布式训练口语传统DNN由本质差别，图分割分区的方法并不有效，开发了新的架构，其实现方法消除了通信和图分割的开销，同时结合了基于流水线的pull-push并行策略。

现有的GNN如GCN，GraphSAGE，GAT的区别主要在于**如何**用图结构学习节点嵌入以及如何使用怎样的神经网络来聚合邻域信息(主体是消息传递范式)。

DNN与GNN的一大区别在于，GNN的样本之间存在依赖性，每个节点稠密特征，GNN与CNN相反，样本多，参数少。P3避免特征传输并且建议独立存储样本和图结构，且使用随机hash分割(更快速)，从来不进行数据传输，将计算最密集的一层push到全部机器用模型并行执行，然后执行其他的k-1层，由此可以形成一个流水线

作者认为在DGL中，数据并行带来了通信的瓶颈，DGL计算过程中80%的时间在等待通信

## 架构：push-pull流水线
* 独立哈希图\特征分割，对点进行随机哈希分割，对于图的特折，对**特征维度**进行分割，F维特征分割为F/N维(N台机器)。每个机器包含部分节点、但是会有全部节点的F/N维特征
* 仍采用mini-batch为主的计算
* 计算图生成：首先节点会pull k-hop的邻居节点(可能会采样)以及其特征，其次现有的框架如DistDGL在**方向传播时**会在每一层都同步梯度
* 计算图执行：首先把第一层push给全部机器，第一层计算压力大，因为输入特征分布在整个集群中；然后每台机器都用自己部分的流水线计算第一层的一部分(activation)(模型并行)，然后各层pull激活后的特征并进行拼装，然后再不能模型并行的部分进行数据并行。因为pull激活后的特征的数据量比较小
* 流水线：P3需要push第一层的部分模型，pull partial activation中间结果，并在反向传播过程中push梯度(反向的每一层都需要同步)，将一个mini-batch的执行分为4部分，包括前向计算的模型并行部分，前向计算的数据并行部分（这两步由数据依赖），反向计算的数据并行部分，反向计算的模型并行部分（这里i昂布由数据依赖），可以调度三个mini-batch

注意：对于layer 1D，即数据并行部分，应该是非线性的(如全连接层)、非元素层级(如卷积)的操作，而且；而1M，即模型并行部分常采用元素层级的操作(如加法)，

future work：pipeline的调度算法，目前时静态的

模型并行部分：第一层先计算部分激活，交换数据，剩余部分进行数据并行(非线性操作不能部分计算)