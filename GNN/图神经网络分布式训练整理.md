## 图神经网络训练框架与分布式训练相关文献阅读
### 文献阅读
* Deep Graph Library: Towards Efficient and Scalable Deep Learning on Graphs ([ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019](https://www.researchgate.net/publication/335617788_Deep_Graph_Library_Towards_Efficient_and_Scalable_Deep_Learning_on_Graphs))
* 流行的GNN训练框架DGL，使用消息传播范式，采用了消息融合技术。[详细阅读](./DGL.md)
---
* DistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs. ([IEEE/ACM 10th Workshop on Irregular Applications: Architectures and Algorithms (IA3)2020: 36-44 Amazon](https://arxiv.org/abs/2010.05337))
* DGL的分布式训练模块，基于DGL实现的分布式图神经网络训练框架。大体思路是：对大图用METIS进行图分割作为预处理采样（**会产生重复点**），得到的子图作为mini-batch在train上训练得到梯度。介绍了GNN分布式训练理念的框架设计思路和一些关键点。[详细阅读](./DistDGL.md)
---
* Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks ([KDD'19](https://www.researchgate.net/publication/334717498_Cluster-GCN_An_Efficient_Algorithm_for_Training_Deep_and_Large_Graph_Convolutional_Networks))
* 用于大规模图的卷积GCN训练，使用vanilla mini-SGD，首先用聚类算法(如metis和graclus)进行划分得到sub-Graph作为簇（目标是使得簇内部的边远大于簇间），用簇作为batch进行训练；其次引入Stochastic Multiple Partitions算法，在每次训练时随机选择若干簇构成一个batch进行训练。总的来说是针对GCN本身的优化，不过提供了一个采样构成batch进行计算的思路[详细阅读](./Cluster-GCN.md)
---
* P3: Distributed Deep Graph Learning at Scale([OSDI'2021])
采用与DistDGL完全不同的结构，基于DGL实现了分布式GNN训练。基于认为GNN的分布式训练口语传统DNN由本质差别，图分割分区的方法并不有效，使用随机hash划分的方式来分割图，同时将数据并行和模型并行混合组成静态流水线，充分运用GPU算力，同时减少了要传输的数据量。同时引入了简单的cache，对于内存够用的情况，将分区保存到多个节点
---
* Dorylus: Affordable, Scalable, and Accurate GNN Training with Distributed CPU Servers and Serverless Threads([OSDI'2021])
* GNN训练的两大问题1)需要高端服务器，购买维护很昂贵2)GPU现存有限，难以包纳数十亿的边，Dorylus结合无服务计算serveless的特点，增强了可伸缩性
---
* Improving the accuracy, scalability, and performance of graph neural networks with roc([MLsys’2020](https://cs.stanford.edu/~zhihao/papers/mlsys20.pdf))
ROC是个分布式多GPU的大规模图的GNN快速训练和推断的框架，能够在多个计算节点上训练全图，解决图划分问题和内存管理问题(动态规划)，待读
---
* PaGraph: Scaling GNN Training on Large Graphs via computation-aware caching([SoCC'2020](https://dl.acm.org/doi/pdf/10.1145/3419111.3421281))
* 数据从CPU加载到GPU再用大量带宽，使用cache来缓存，待读
---
* DistGNN: Scalable Distributed Training for Large-Scale Graph Neural Networks ([intel preprint 2021](https://www.researchgate.net/publication/350875953_DistGNN_Scalable_Distributed_Training_for_Large-Scale_Graph_Neural_Networks))
* 使用DGL进行分布式训练，用CPU集群进行full-batch learning，改进了SpMM稀疏矩阵乘法
---
Gpipe和PipeDream，大规模、分布式、流水线化的DNN训练，可以用于云基础设施
---
## 时间线
ROC < DistDGL < P3 ~ Dorylus

## 总结：
### 图神经网络模型
发掘结构体征
* 深度学习
    * GCN：直推式学习，适用于半监督、无监督，不具备泛化能力
    * GraphSAGE，ClusterGCN等
* PageRank等算法，知识图谱、社区发掘等社会计算领域问题
* 思考：是否可以探索新的GNN模型来使之便于在集群上进行训练，如借用Cluster-GCN，但是这样的话问题变成了部署高效的针对某一种GNN模型，而不是对整个GNN类别的底层架构的优化
* 备忘：对与GCN，可训练参数形如(in_feature_dim, out_feature_dim)

### 探索方向：
* 底层优化：
合理的稀疏矩阵算法（主要的稀疏矩阵的乘法），主要是对SpMM、SDDMM优化，但是对于大图，邻接矩阵$A$本身就很大，此时是否可以具备并行或者分布式计算的必要？属于底层算子
* operator分布式部署，
    * 并行：子图划分，分别进行计算等思路，已有例子如clusterGCN和DistDGL
    * 分布式：常用图采样+Paramer server或All reduce算法
* 云部署，将GNN的训练或者部署分发部署到云端

GNN训练的主要瓶颈：存储计算比较小（大量保存中间的embedding以及信息传递模型中边上的体征占用空间大）