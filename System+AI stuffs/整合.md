# AI+system 整合

* A Self-Optimized Generic Workload Prediction Framework for Cloud Computing IPDPS'2020

工作负载，工作到达率、用户作业请求率，下次到达时间间隔。预测有一定难度，当前都是对特定工作手动调整达到最大的准确性，可以用于自动方所或者调度。
LoadDynamic，对任意工作负载进行高准确率预测，用公有云应用，科学应用，数据中心工作和web应用来测试。
LSTM模型，用贝叶斯优化调超参数，在google公有云上自动放缩。

问题定义：对于运行ML训练推理，将作业流分割小的时间间隔，并用间隔中的数目进行表述，定义为JAR，Ji与之前n个JAR有相关性和依赖关系（理论支持）。超参数搜索

实验：不同类型：循环、突发、增长，用4种类型的14个超参数，包括维基百科web服务、HPC类型的Grid Workload Archive平台的LCG数据、微软azure公有云、谷歌数据中心共计5个workload trace

metric: mean absolute percentage error (MAPE): $\frac{100\%}{n}\sum_{n}\left|\frac{P_i-J_i}{J_i}\right|$
baseline: CloudInsight(21种选举), CloudScale(FFT), Wood(线性回归)

ClodScale、wood不能应付模式复杂的workload，而CloudInsight的超参数固定，未必符合当前的workload
此外暴搜需要1天-6周，而LoadDynamic最多3h而且也meta只少1%，此外，在时间间隔较小时meta通常较大，因为JARS更小，容易受到随机波动的请求的影响(缺少可以观察的模式)而对于大规模的workload，哪怕时间间隔小，JARS也足够大

auto-scaling自动放缩策略：在谷歌云，一个job对应一个vm，用一个云套件的内存分析benchmark作为job来模拟机器学习的推理和请求任务，记录每个间隔完成全部任务的时间。
TODO:其它超参数、在线调整模型，因为负载可能会变化

缺点：LSTM模型从有限的workload trace种训练，可能过拟合，不适应真实环境；此外超参数对与精度影响较大，本文的贡献在于结合了超参数搜索

方向：tcn，temporal transformer