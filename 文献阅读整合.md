# 8/10-8/20

## 分布式机器学习文献阅读
* A Unified Architecture for Accelerating Distributed DNN Training in Heterogeneous GPU/CPU Clusters ([OSDI’2020](https://arxiv.org/pdf/1807.08887.pdf))
* 利用集群中闲置的GPU机器的CPU算力，介绍了常用分布式机器学习算法：ALL-reduce、parameter server(PS)。提出Summation service，在PS算法中梯度求和部分与参数更新在PS上进行；而Summation service中，梯度更新仍由GPU进行，参数聚合在CPU上计算（可以利用AVX等CPU自带的指令集）[详细阅读](./BytePS.md)
---

* Ray: A Distributed Framework for Emerging AI Applications([OSDI'18](https://arxiv.org/abs/1712.05889))
* 分布式机器学习(强化学习)框架[详细阅读](./Ray-paper.md)
---
## 图神经网络训练框架与分布式训练相关文献阅读
### 文献阅读
* Deep Graph Library: Towards Efficient and Scalable Deep Learning on Graphs ([ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019](https://www.researchgate.net/publication/335617788_Deep_Graph_Library_Towards_Efficient_and_Scalable_Deep_Learning_on_Graphs))
* 流行的GNN训练框架DGL，使用消息传播范式，采用了消息融合技术。[详细阅读](./DGL.md)
---
* DistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs. ([IEEE/ACM 10th Workshop on Irregular Applications: Architectures and Algorithms (IA3)2020: 36-44 Amazon](https://arxiv.org/abs/2010.05337))
* DGL的分布式训练模块，基于DGL实现的分布式图神经网络训练框架。大体思路是：对大图用METIS进行图分割作为预处理采样（**会产生重复点**），得到的子图作为mini-batch在train上训练得到梯度。介绍了GNN分布式训练理念的框架设计思路和一些关键点。[详细阅读](./DistDGL.md)
---
* Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks ([KDD'19](https://www.researchgate.net/publication/334717498_Cluster-GCN_An_Efficient_Algorithm_for_Training_Deep_and_Large_Graph_Convolutional_Networks))
* 用于大规模图的卷积GCN训练，使用vanilla mini-SGD，首先用聚类算法(如metis和graclus)进行划分得到sub-Graph作为簇（目标是使得簇内部的边远大于簇间），用簇作为batch进行训练；其次引入Stochastic Multiple Partitions算法，在每次训练时随机选择若干簇构成一个batch进行训练。总的来说是针对GCN本身的优化，不过提供了一个采样构成batch进行计算的思路[详细阅读](./Cluster-GCN.md)
---
* P3: Distributed Deep Graph Learning at Scale([OSDI'2021])
采用与DistDGL完全不同的结构，基于DGL实现了分布式GNN训练。基于认为GNN的分布式训练口语传统DNN由本质差别，图分割分区的方法并不有效，使用随机hash划分的方式来分割图，同时将数据并行和模型并行混合，充分运用GPU算力，同时减少了要传输的数据量。同时引入了简单的cache，对于内存够用的情况，将分区保存到多个节点
---
* Dorylus: Affordable, Scalable, and Accurate GNN Training with Distributed CPU Servers and Serverless Threads([OSDI'2021])
* GNN训练的两大问题1)需要高端服务器，购买维护很昂贵2)GPU现存有限，难以包纳数十亿的边，Dorylus结合无服务计算serveless的特点，增强了可伸缩性
---
* Improving the accuracy, scalability, and performance of graph neural networks with roc([MLsys’2020](https://cs.stanford.edu/~zhihao/papers/mlsys20.pdf))
ROC是个分布式多GPU的大规模图的GNN快速训练和推断的框架，能够在多个计算节点上训练全图，解决图划分问题和内存管理问题(动态规划)，待读
---
* PaGraph Scaling GNN Training on Large Graphs via computation-aware caching([SoCC'2020](https://dl.acm.org/doi/pdf/10.1145/3419111.3421281))
* 数据从CPU加载到GPU再用大量带宽，使用cache来缓存，待读
---
* DistGNN: Scalable Distributed Training for Large-Scale Graph Neural Networks ([intel preprint 2021](https://www.researchgate.net/publication/350875953_DistGNN_Scalable_Distributed_Training_for_Large-Scale_Graph_Neural_Networks))
* 使用DGL进行分布式训练，用**CPU集群**进行**full-batch** learning，改进了SpMM稀疏矩阵乘法
---
## 时间线
ROC < DistDGL < P3 ~ Dorylus

### 总结：
#### 图神经网络模型
发掘结构体征
* 深度学习
    * GCN：直推式学习，适用于半监督、无监督，不具备泛化能力
    * GraphSAGE，clusterGCN等
* PageRank等算法，知识图谱、社区发掘等社会计算领域问题

#### 探索方向：
* 工具：DGL，PYG等，目前各论文基本采用DGL+pytorch为后端
* 底层优化：
合理的稀疏矩阵算法（主要的稀疏矩阵的乘法），主要是对SpMM、SDDMM优化，但是对于大图，邻接矩阵$A$本身就很大，此时是否可以具备并行或者分布式计算的必要？属于底层算子，例如DistGNN
* operator的分布式部署，
    * 并行：子图划分，分别进行计算等思路，已有例子如ROC，DistDGL
    * 模型并行+数据并行，如P3，减少分区时间和交换的信息量，外交流水线技术
    * DNN分布式：用DGL，直接将pytorch作为后端
* serveless部署，Dorylus

GNN训练的主要瓶颈：存储计算比较小（大量保存中间的embedding以及信息传递模型中边上的体征占用空间大）